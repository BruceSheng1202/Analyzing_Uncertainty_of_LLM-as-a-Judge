{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_number = {\n",
    "    'one': 1,\n",
    "    'two': 2,\n",
    "    'three': 3,\n",
    "    'four': 4,\n",
    "    'five': 5\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "alpha = 0.10\n",
    "\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# !wget https://files.pythonhosted.org/packages/py3/R/R2CCP/R2CCP-0.0.8-py3-none-any.whl\n",
    "# !pip install R2CCP-0.0.8-py3-none-any.whl --no-deps\n",
    "import os\n",
    "os.makedirs('model_paths', exist_ok=True)\n",
    "\n",
    "# !pip install configargparse pytorch_lightning torchvision\n",
    "from R2CCP.main import R2CCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from R2CCP.main import R2CCP\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "\n",
    "def merge_intervals(sample_intervals):\n",
    "    if not sample_intervals:\n",
    "        return (1,5)\n",
    "    lows = [low for low, high in sample_intervals]\n",
    "    highs = [high for low, high in sample_intervals]\n",
    "    return (min(lows), max(highs))\n",
    "\n",
    "def range_modification(y_qlow, y_qup, range_low,  range_up):\n",
    "    y_qlow = np.clip(y_qlow, range_low, range_up)\n",
    "    y_qup = np.clip(y_qup, range_low, range_up)\n",
    "    return y_qlow, y_qup\n",
    "\n",
    "def run_experiment(X, y, seed, dimension, dataset):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    X = X.to_numpy().astype(np.float32)\n",
    "    y = y.to_numpy().astype(np.float32)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_cal, X_test, y_cal, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "\n",
    "    # X_cal = X_cal[:int(len(X_cal) * cal_size)]\n",
    "    # y_cal = y_cal[:int(len(y_cal) * cal_size)]\n",
    "    \n",
    "    if os.path.exists('model_paths/model_save_destination.pth'):\n",
    "        os.remove('model_paths/model_save_destination.pth')\n",
    "\n",
    "    model = R2CCP({'model_path': 'model_paths/model_save_destination.pth', 'max_epochs': 100, 'alpha': alpha})\n",
    "    model.fit(X_cal, y_cal.flatten())\n",
    "    intervals = model.get_intervals(X_test)\n",
    "    intervals = [merge_intervals(sample_intervals) for sample_intervals in intervals]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'low':    [iv[0] for iv in intervals],\n",
    "        'up':     [iv[1] for iv in intervals],\n",
    "        'y_test': y_test\n",
    "    })\n",
    "\n",
    "    df.to_csv(f'R2CCP_{dataset}_{dimension}_{seed}.csv', index=False)\n",
    "    \n",
    "    # m = 13\n",
    "    # target_idx = np.linspace(3, 15, m)-3\n",
    "\n",
    "    # adjusted_intervals = [\n",
    "    # [\n",
    "    #     (\n",
    "    #         next((num for num in target_idx if abs(low - num) < 1/6), low),\n",
    "    #         next((num for num in target_idx if abs(high - num) < 1/6), high)\n",
    "    #     )\n",
    "    #     for low, high in sample_intervals\n",
    "    # ]\n",
    "    # for sample_intervals in intervals]\n",
    "\n",
    "    # intervals = adjusted_intervals\n",
    "\n",
    "    in_interval = [\n",
    "        (low <= y_true <= high)\n",
    "        for (low, high), y_true in zip(intervals, y_test)\n",
    "    ]\n",
    "    coverage_rate  = np.mean(in_interval)\n",
    "    average_width = np.mean([high - low for low, high in intervals])\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1) \n",
    "\n",
    "    print(f\"Seed: {seed}, Width: {average_width:.4f}, Coverage: {coverage_rate:.4f}\")\n",
    "\n",
    "    return average_width, coverage_rate\n",
    "\n",
    "def calculate_statistics(X, y, num_runs=100, seed_start=1, dimension = 'consistency', dataset='summeval'):\n",
    "    from tqdm import tqdm\n",
    "    width = []\n",
    "    coverage = []\n",
    "    for i in tqdm(range(num_runs), desc=\"Running experiments\"):\n",
    "        seed = seed_start + i\n",
    "        try:\n",
    "            average_width, coverage_rate = run_experiment(X, y, seed, dimension, dataset)\n",
    "            width.append(average_width)\n",
    "            coverage.append(coverage_rate)\n",
    "            print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n",
    "        except IndexError as e:\n",
    "            print(f\"Skipping seed {seed} due to error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    mean_width = np.mean(width)\n",
    "    std_width = np.std(width)\n",
    "    mean_coverage = np.mean(coverage)\n",
    "    std_coverage = np.std(coverage)\n",
    "\n",
    "    print(\"\\nSummary of R2CCP:\")\n",
    "    print(f\"Width: {mean_width:.4f}, {std_width:.4f}\")\n",
    "    print(f\"Coverage: {mean_coverage:.4f}, {std_coverage:.4f}\")\n",
    "\n",
    "    return  width, coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 125.00it/s, v_num=26293]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 118.34it/s, v_num=26293]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Width: 0.5978, Coverage: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 235.29it/s, v_num=26294]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 224.70it/s, v_num=26294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Width: 2.1678, Coverage: 0.8575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 84.23it/s, v_num=26295]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 81.16it/s, v_num=26295]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Width: 0.8503, Coverage: 0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 86.58it/s, v_num=26296]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 20/20 [00:00<00:00, 83.34it/s, v_num=26296]\n",
      "Seed: 42, Width: 2.1415, Coverage: 0.9325\n"
     ]
    }
   ],
   "source": [
    "folder_path = f'./model_logits/dsr1/'\n",
    "\n",
    "dataset = 'Summeval'\n",
    "data = {}\n",
    "for dimension in [\"consistency\", \"coherence\", \"fluency\", \"relevance\"]:\n",
    "    file_path = os.path.join(folder_path, f\"Summeval_{dimension}_logits.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    run_experiment(X, y, 42, dimension, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 223.58it/s, v_num=26313]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 210.50it/s, v_num=26313]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Width: 1.9116, Coverage: 0.8871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 205.72it/s, v_num=26314]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 196.72it/s, v_num=26314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Width: 1.2829, Coverage: 0.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 229.26it/s, v_num=26315]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 215.54it/s, v_num=26315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Width: 1.1641, Coverage: 0.9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | MLPModel | 80.2 K | train\n",
      "1 | smax  | Softmax  | 0      | train\n",
      "-------------------------------------------\n",
      "80.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.2 K    Total params\n",
      "0.321     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 217.18it/s, v_num=26316]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 18/18 [00:00<00:00, 202.28it/s, v_num=26316]\n",
      "Seed: 42, Width: 1.8049, Coverage: 0.8986\n"
     ]
    }
   ],
   "source": [
    "folder_path = f'./model_logits/dsr1/'\n",
    "\n",
    "dataset = 'Dialsumm'\n",
    "data = {}\n",
    "for dimension in [\"consistency\", \"coherence\", \"fluency\", \"relevance\"]:\n",
    "    file_path = os.path.join(folder_path, f\"{dataset}_{dimension}_logits.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    run_experiment(X, y, 42, dimension, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = f'./model_logits/qwen/'\n",
    "\n",
    "data = {}\n",
    "for dimension in [\"cosmos\", \"drop\", \"esnli\", \"gsm8k\"]:\n",
    "        file_path = os.path.join(folder_path, f\"SocREval_{dimension}_logits.csv\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "        width, coverage = calculate_statistics(X, y, num_runs=30, seed_start=1, dimension=dimension, dataset='SocREval')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
