{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b5f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "alpha = 0.10\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# !wget https://files.pythonhosted.org/packages/py3/R/R2CCP/R2CCP-0.0.8-py3-none-any.whl\n",
    "# !pip install R2CCP-0.0.8-py3-none-any.whl --no-deps\n",
    "import os\n",
    "os.makedirs('model_paths', exist_ok=True)\n",
    "\n",
    "# !pip install configargparse pytorch_lightning torchvision\n",
    "from R2CCP.main import R2CCP\n",
    "\n",
    "def merge_intervals(sample_intervals):\n",
    "    if not sample_intervals:\n",
    "        return (1,5)\n",
    "    lows = [low for low, high in sample_intervals]\n",
    "    highs = [high for low, high in sample_intervals]\n",
    "    return (min(lows), max(highs))\n",
    "\n",
    "def boundary_adjustment(value, label_set, threshold=0):\n",
    "    threshold_max = (label_set[-1] - label_set[0]) / (len(label_set) - 1) / 2\n",
    "    threshold = min(threshold_max, threshold)\n",
    "    adjusted_value = next((num for num in label_set if abs(num - value) <= threshold+0.01), value)\n",
    "    \n",
    "    return adjusted_value\n",
    "\n",
    "def coverage_and_width(low, up, y_test):\n",
    "    width = up - low\n",
    "    coverage = np.mean((low <= y_test) & (y_test <= up))\n",
    "    return width.mean(), coverage.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model_name in {'4omini', 'dsr1', 'qwen'}:\n",
    "    for dimension in {'consistency', 'coherence', 'fluency', 'relevance'}:\n",
    "        cal_data = pd.read_csv(f'../model_logits/{model_name}/Summeval_{dimension}_logits.csv')\n",
    "        X_cal = cal_data.iloc[:, :-1].to_numpy().astype(np.float32)\n",
    "        y_cal = cal_data.iloc[:, -1].to_numpy().astype(np.float32)\n",
    "        test_data = pd.read_csv(f'../model_logits/{model_name}/Dialsumm_{dimension}_logits.csv')\n",
    "        X_test = test_data.iloc[:, :-1].to_numpy().astype(np.float32)\n",
    "        y_test = test_data.iloc[:, -1].to_numpy().astype(np.float32)\n",
    "\n",
    "        if os.path.exists('model_paths/model_save_destination.pth'):\n",
    "            os.remove('model_paths/model_save_destination.pth')\n",
    "\n",
    "        model = R2CCP({'model_path': 'model_paths/model_save_destination.pth', 'max_epochs': 100, 'alpha': 0.1})\n",
    "        model.fit(X_cal, y_cal.flatten())\n",
    "        intervals = model.get_intervals(X_test)\n",
    "        intervals = [merge_intervals(sample_intervals) for sample_intervals in intervals]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'low':    [iv[0] for iv in intervals],\n",
    "            'up':     [iv[1] for iv in intervals],\n",
    "            'y_test': y_test\n",
    "            })\n",
    "\n",
    "        df.to_csv(f'R2CCP_{dimension}_{model_name}_summeval2dialsumm.csv', index=False)\n",
    "\n",
    "        in_interval = [\n",
    "            (low <= y_true <= high)\n",
    "            for (low, high), y_true in zip(intervals, y_test)\n",
    "            ]\n",
    "        coverage_rate  = np.mean(in_interval)\n",
    "        average_width = np.mean([high - low for low, high in intervals])\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"Width: {average_width:.4f}, Coverage: {coverage_rate:.4f}\")\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'dimension': dimension,\n",
    "            'coverage_rate': coverage_rate,\n",
    "            'average_width': average_width\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba36b526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'dsr1',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.4657142857142857,\n",
       "  'average_width': 0.6924895087310247},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.24,\n",
       "  'average_width': 0.5956422196967261},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.9271428571428572,\n",
       "  'average_width': 1.9237895865951267},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.8185714285714286,\n",
       "  'average_width': 1.7927325912032808},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.4742857142857143,\n",
       "  'average_width': 0.8462530732154846},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.20357142857142857,\n",
       "  'average_width': 0.5863682071651731},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.72,\n",
       "  'average_width': 2.067312071578843},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.8742857142857143,\n",
       "  'average_width': 1.9778050071001052},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.7907142857142857,\n",
       "  'average_width': 1.3494397498880113},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.18454935622317598,\n",
       "  'average_width': 0.5430840393674903},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.8607142857142858,\n",
       "  'average_width': 2.274889868753297},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.8481375358166189,\n",
       "  'average_width': 1.912433155884374}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536e863c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'dsr1',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.57,\n",
       "  'average_width': 0.6531071428571429},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.30714285714285716,\n",
       "  'average_width': 0.5562642857142858},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.9435714285714286,\n",
       "  'average_width': 1.921557142857143},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.8707142857142857,\n",
       "  'average_width': 1.7732285714285714},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.6292857142857143,\n",
       "  'average_width': 0.8376357142857144},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.30642857142857144,\n",
       "  'average_width': 0.5536857142857143},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.7657142857142857,\n",
       "  'average_width': 2.0643214285714286},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.9028571428571428,\n",
       "  'average_width': 1.9797285714285713},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.865,\n",
       "  'average_width': 1.35215},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.31258941344778257,\n",
       "  'average_width': 0.5233118741058657},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.8957142857142857,\n",
       "  'average_width': 2.271028571428572},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.9154727793696275,\n",
       "  'average_width': 1.8949355300859598}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set = np.array([1, 1.33, 1.67, 2, 2.33, 2.67, 3, 3.33, 3.67, 4, 4.33, 4.67, 5])\n",
    "adjustment = 0.17\n",
    "\n",
    "results = []\n",
    "for model_name in {'4omini', 'dsr1', 'qwen'}:\n",
    "    for dimension in {'consistency', 'coherence', 'fluency', 'relevance'}:\n",
    "        data = pd.read_csv(f'R2CCP_{dimension}_{model_name}_summeval2dialsumm.csv')\n",
    "        data = data.round(2)\n",
    "        data['low'] = data['low'].apply(lambda x: boundary_adjustment(x, label_set, adjustment))\n",
    "        data['up'] = data['up'].apply(lambda x: boundary_adjustment(x, label_set, adjustment))\n",
    "        width, coverage = coverage_and_width(data['low'], data['up'], data['y_test'])\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'dimension': dimension,\n",
    "            'coverage_rate': coverage,\n",
    "            'average_width': width\n",
    "        })\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model_name in {'4omini', 'dsr1', 'qwen'}:\n",
    "    for dimension in {'consistency', 'coherence', 'fluency', 'relevance'}:\n",
    "        cal_data = pd.read_csv(f'../model_logits/{model_name}/Dialsumm_{dimension}_logits.csv')\n",
    "        X_cal = cal_data.iloc[:, :-1].to_numpy().astype(np.float32)\n",
    "        y_cal = cal_data.iloc[:, -1].to_numpy().astype(np.float32)\n",
    "        test_data = pd.read_csv(f'../model_logits/{model_name}/Summeval_{dimension}_logits.csv')\n",
    "        X_test = test_data.iloc[:, :-1].to_numpy().astype(np.float32)\n",
    "        y_test = test_data.iloc[:, -1].to_numpy().astype(np.float32)\n",
    "\n",
    "        if os.path.exists('model_paths/model_save_destination.pth'):\n",
    "            os.remove('model_paths/model_save_destination.pth')\n",
    "\n",
    "        model = R2CCP({'model_path': 'model_paths/model_save_destination.pth', 'max_epochs': 100, 'alpha': 0.1})\n",
    "        model.fit(X_cal, y_cal.flatten())\n",
    "        intervals = model.get_intervals(X_test)\n",
    "        intervals = [merge_intervals(sample_intervals) for sample_intervals in intervals]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'low':    [iv[0] for iv in intervals],\n",
    "            'up':     [iv[1] for iv in intervals],\n",
    "            'y_test': y_test\n",
    "            })\n",
    "\n",
    "        df.to_csv(f'R2CCP_{dimension}_{model_name}_dialsumm2summeval.csv', index=False)\n",
    "\n",
    "        in_interval = [\n",
    "            (low <= y_true <= high)\n",
    "            for (low, high), y_true in zip(intervals, y_test)\n",
    "            ]\n",
    "        coverage_rate  = np.mean(in_interval)\n",
    "        average_width = np.mean([high - low for low, high in intervals])\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"Width: {average_width:.4f}, Coverage: {coverage_rate:.4f}\")\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'dimension': dimension,\n",
    "            'coverage_rate': coverage_rate,\n",
    "            'average_width': average_width\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b9c77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'dsr1',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.359375,\n",
       "  'average_width': 1.1209421215951443},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.50375,\n",
       "  'average_width': 1.879784333333373},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.52375,\n",
       "  'average_width': 1.34417592972517},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.801875,\n",
       "  'average_width': 1.726801937893033},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.271875,\n",
       "  'average_width': 1.1638392074406148},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.3775,\n",
       "  'average_width': 1.5958447203040123},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.483125,\n",
       "  'average_width': 1.4909820595383645},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.77625,\n",
       "  'average_width': 1.5879724637418986},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.536875,\n",
       "  'average_width': 1.3163820619136095},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.665,\n",
       "  'average_width': 1.8366421043872834},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.565,\n",
       "  'average_width': 1.7644335271418095},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.828125,\n",
       "  'average_width': 1.8922668456286191}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e292511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'dsr1',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.82375,\n",
       "  'average_width': 1.1595875},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.699375,\n",
       "  'average_width': 1.8781875000000001},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.6025,\n",
       "  'average_width': 1.3318125},\n",
       " {'model': 'dsr1',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.8625,\n",
       "  'average_width': 1.7228937500000001},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.9,\n",
       "  'average_width': 1.21904375},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.5925,\n",
       "  'average_width': 1.60364375},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.57375,\n",
       "  'average_width': 1.5208812500000002},\n",
       " {'model': 'qwen',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.845,\n",
       "  'average_width': 1.5615312499999998},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'fluency',\n",
       "  'coverage_rate': 0.920625,\n",
       "  'average_width': 1.3340062499999998},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'consistency',\n",
       "  'coverage_rate': 0.805,\n",
       "  'average_width': 1.8489937500000002},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'coherence',\n",
       "  'coverage_rate': 0.6325,\n",
       "  'average_width': 1.7727687500000002},\n",
       " {'model': '4omini',\n",
       "  'dimension': 'relevance',\n",
       "  'coverage_rate': 0.90875,\n",
       "  'average_width': 1.89443125}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set = np.array([1, 1.33, 1.67, 2, 2.33, 2.67, 3, 3.33, 3.67, 4, 4.33, 4.67, 5])\n",
    "adjustment = 0.17\n",
    "\n",
    "results = []\n",
    "for model_name in {'4omini', 'dsr1', 'qwen'}:\n",
    "    for dimension in {'consistency', 'coherence', 'fluency', 'relevance'}:\n",
    "        data = pd.read_csv(f'R2CCP_{dimension}_{model_name}_dialsumm2summeval.csv')\n",
    "        data = data.round(2)\n",
    "        data['low'] = data['low'].apply(lambda x: boundary_adjustment(x, label_set, adjustment))\n",
    "        data['up'] = data['up'].apply(lambda x: boundary_adjustment(x, label_set, adjustment))\n",
    "        width, coverage = coverage_and_width(data['low'], data['up'], data['y_test'])\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'dimension': dimension,\n",
    "            'coverage_rate': coverage,\n",
    "            'average_width': width\n",
    "        })\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324f60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labels for fluency:\n",
      "y_test\n",
      "5.00    1150\n",
      "4.67     141\n",
      "4.33     112\n",
      "4.00      39\n",
      "2.67      34\n",
      "3.00      30\n",
      "3.67      27\n",
      "3.33      18\n",
      "1.67      17\n",
      "2.33      11\n",
      "2.00      11\n",
      "1.33       5\n",
      "1.00       5\n",
      "Name: count, dtype: int64\n",
      "Distribution of labels for consistency:\n",
      "y_test\n",
      "5.00    1306\n",
      "4.67      81\n",
      "4.33      44\n",
      "1.67      39\n",
      "2.67      30\n",
      "2.00      24\n",
      "1.33      21\n",
      "2.33      19\n",
      "1.00      14\n",
      "4.00       8\n",
      "3.00       7\n",
      "3.67       7\n",
      "Name: count, dtype: int64\n",
      "Distribution of labels for coherence:\n",
      "y_test\n",
      "4.33    270\n",
      "4.00    174\n",
      "2.67    149\n",
      "3.00    141\n",
      "3.67    135\n",
      "3.33    132\n",
      "4.67    124\n",
      "2.33    123\n",
      "5.00    111\n",
      "1.67    103\n",
      "2.00    100\n",
      "1.33     25\n",
      "1.00     13\n",
      "Name: count, dtype: int64\n",
      "Distribution of labels for relevance:\n",
      "y_test\n",
      "4.33    318\n",
      "4.00    302\n",
      "3.67    217\n",
      "4.67    187\n",
      "3.33    155\n",
      "3.00    120\n",
      "2.67     87\n",
      "5.00     83\n",
      "2.33     62\n",
      "2.00     33\n",
      "1.67     25\n",
      "1.33      6\n",
      "1.00      5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for dimension in {'consistency', 'coherence', 'fluency', 'relevance'}:\n",
    "        data = pd.read_csv(f'R2CCP_{dimension}_dsr1_dialsumm2summeval.csv')\n",
    "        print(f\"Distribution of labels for {dimension}:\")\n",
    "        label = data['y_test'].round(2)\n",
    "        value_counts = label.value_counts()\n",
    "        print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a539d405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labels for fluency:\n",
      "y_test\n",
      "4.67    588\n",
      "4.33    400\n",
      "4.00    204\n",
      "3.67     92\n",
      "3.33     41\n",
      "2.67     29\n",
      "3.00     21\n",
      "2.33     10\n",
      "5.00      9\n",
      "2.00      4\n",
      "1.67      1\n",
      "1.33      1\n",
      "Name: count, dtype: int64\n",
      "Distribution of labels for consistency:\n",
      "y_test\n",
      "4.00    235\n",
      "3.67    212\n",
      "4.33    209\n",
      "4.67    190\n",
      "3.33    121\n",
      "3.00     99\n",
      "1.00     61\n",
      "2.67     61\n",
      "1.67     51\n",
      "2.33     48\n",
      "2.00     43\n",
      "5.00     40\n",
      "1.33     30\n",
      "Name: count, dtype: int64\n",
      "Distribution of labels for coherence:\n",
      "y_test\n",
      "4.67    413\n",
      "4.33    350\n",
      "4.00    191\n",
      "3.67    133\n",
      "3.33     91\n",
      "3.00     76\n",
      "5.00     71\n",
      "2.67     46\n",
      "2.33     20\n",
      "2.00      5\n",
      "1.67      3\n",
      "1.33      1\n",
      "Name: count, dtype: int64\n",
      "Distribution of labels for relevance:\n",
      "y_test\n",
      "3.67    281\n",
      "4.00    236\n",
      "3.33    220\n",
      "4.33    154\n",
      "3.00     89\n",
      "4.67     80\n",
      "5.00     75\n",
      "2.67     70\n",
      "1.67     47\n",
      "2.33     41\n",
      "1.00     40\n",
      "2.00     35\n",
      "1.33     32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for dimension in {'consistency', 'coherence', 'fluency', 'relevance'}:\n",
    "        data = pd.read_csv(f'R2CCP_{dimension}_dsr1_summeval2dialsumm.csv')\n",
    "        print(f\"Distribution of labels for {dimension}:\")\n",
    "        label = data['y_test'].round(2)\n",
    "        value_counts = label.value_counts()\n",
    "        print(value_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
