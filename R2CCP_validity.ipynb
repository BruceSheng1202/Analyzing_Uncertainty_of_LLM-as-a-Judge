{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_number = {\n",
    "    'one': 1,\n",
    "    'two': 2,\n",
    "    'three': 3,\n",
    "    'four': 4,\n",
    "    'five': 5\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "alpha = 0.10\n",
    "\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# !wget https://files.pythonhosted.org/packages/py3/R/R2CCP/R2CCP-0.0.8-py3-none-any.whl\n",
    "# !pip install R2CCP-0.0.8-py3-none-any.whl --no-deps\n",
    "import os\n",
    "os.makedirs('model_paths', exist_ok=True)\n",
    "\n",
    "# !pip install configargparse pytorch_lightning torchvision\n",
    "from R2CCP.main import R2CCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from R2CCP.main import R2CCP\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "\n",
    "def merge_intervals(sample_intervals):\n",
    "    if not sample_intervals:\n",
    "        return (1,5)\n",
    "    lows = [low for low, high in sample_intervals]\n",
    "    highs = [high for low, high in sample_intervals]\n",
    "    return (min(lows), max(highs))\n",
    "\n",
    "def range_modification(y_qlow, y_qup, range_low,  range_up):\n",
    "    y_qlow = np.clip(y_qlow, range_low, range_up)\n",
    "    y_qup = np.clip(y_qup, range_low, range_up)\n",
    "    return y_qlow, y_qup\n",
    "\n",
    "def run_experiment(X, y, dimension, dataset):\n",
    "\n",
    "    X = X.to_numpy().astype(np.float32)\n",
    "    y = y.to_numpy().astype(np.float32)\n",
    "\n",
    "    split_index = len(X) // 2 \n",
    "\n",
    "    X_first_half = X[:split_index]\n",
    "    X_second_half = X[split_index:]\n",
    "    y_first_half = y[:split_index]\n",
    "    y_second_half = y[split_index:]\n",
    "\n",
    "    X_cal, X_test = X_first_half, X_second_half\n",
    "    y_cal, y_test = y_first_half, y_second_half\n",
    "    \n",
    "    if os.path.exists('model_paths/model_save_destination.pth'):\n",
    "        os.remove('model_paths/model_save_destination.pth')\n",
    "\n",
    "    model = R2CCP({'model_path': 'model_paths/model_save_destination.pth', 'max_epochs': 100, 'alpha': alpha})\n",
    "    model.fit(X_cal, y_cal.flatten())\n",
    "    intervals = model.get_intervals(X_test)\n",
    "    intervals = [merge_intervals(sample_intervals) for sample_intervals in intervals]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'low':    [iv[0] for iv in intervals],\n",
    "        'up':     [iv[1] for iv in intervals],\n",
    "        'y_test': y_test\n",
    "    })\n",
    "\n",
    "    df.to_csv(f'R2CCP_{dataset}_{dimension}_halfhalf.csv', index=False)\n",
    "    \n",
    "    # m = 13\n",
    "    # target_idx = np.linspace(3, 15, m)-3\n",
    "\n",
    "    # adjusted_intervals = [\n",
    "    # [\n",
    "    #     (\n",
    "    #         next((num for num in target_idx if abs(low - num) < 1/6), low),\n",
    "    #         next((num for num in target_idx if abs(high - num) < 1/6), high)\n",
    "    #     )\n",
    "    #     for low, high in sample_intervals\n",
    "    # ]\n",
    "    # for sample_intervals in intervals]\n",
    "\n",
    "    # intervals = adjusted_intervals\n",
    "\n",
    "    in_interval = [\n",
    "        (low <= y_true <= high)\n",
    "        for (low, high), y_true in zip(intervals, y_test)\n",
    "    ]\n",
    "    coverage_rate  = np.mean(in_interval)\n",
    "    average_width = np.mean([high - low for low, high in intervals])\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1) \n",
    "\n",
    "    print(f\"Width: {average_width:.4f}, Coverage: {coverage_rate:.4f}\")\n",
    "\n",
    "    return average_width, coverage_rate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = f'../model_logits/4omini/'\n",
    "\n",
    "# dataset = 'Summeval'\n",
    "# data = {}\n",
    "# for dimension in [\"consistency\", \"coherence\", \"fluency\", \"relevance\"]:\n",
    "#     file_path = os.path.join(folder_path, f\"Summeval_{dimension}_logits.csv\")\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     X = df.iloc[:, :-1]\n",
    "#     y = df.iloc[:, -1]\n",
    "#     average_width, coverage_rate = run_experiment(X, y, dimension, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f'../model_logits/4omini/'\n",
    "\n",
    "dataset = 'Summeval'\n",
    "data = {}\n",
    "# for dimension in [\"consistency\", \"coherence\", \"fluency\", \"relevance\"]:\n",
    "dimension = \"consistency\"\n",
    "file_path = os.path.join(folder_path, f\"Summeval_{dimension}_logits.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X = X.to_numpy().astype(np.float32)\n",
    "y = y.to_numpy().astype(np.float32)\n",
    "\n",
    "split_index = len(X) // 2 \n",
    "\n",
    "X_first_half = X[:split_index]\n",
    "X_second_half = X[split_index:]\n",
    "y_first_half = y[:split_index]\n",
    "y_second_half = y[split_index:]\n",
    "\n",
    "X_cal, X_test = X_first_half, X_second_half\n",
    "y_cal, y_test = y_first_half, y_second_half\n",
    "\n",
    "if os.path.exists('model_paths/model_save_destination.pth'):\n",
    "    os.remove('model_paths/model_save_destination.pth')\n",
    "\n",
    "model = R2CCP({'model_path': 'model_paths/model_save_destination.pth', 'max_epochs': 100, 'alpha': alpha})\n",
    "model.fit(X_cal, y_cal.flatten())\n",
    "\n",
    "# Summevalâ€“Consistency, GPT-4o, Lines 7493 & 7498 in response json\n",
    "item93_10 = [-12.6856, -9.0606, -5.0606003, -1.0606002,-0.43560016]\n",
    "item93_11 = [-11.674633, -7.674633, -3.674633, -0.5496331, -0.9246331]\n",
    "\n",
    "X_test = np.array([item93_10, item93_11])\n",
    "intervals = model.get_intervals(X_test)\n",
    "intervals = [merge_intervals(sample_intervals) for sample_intervals in intervals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.6123738288879395, 5.0), (4.625612258911133, 5.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax of item93_10: [3.09666397e-06 1.16201458e-04 6.34438274e-03 3.46391595e-01\n",
      " 6.47144724e-01]\n",
      "Softmax of item93_11: [8.50970663e-06 4.64614239e-04 2.53670780e-02 5.77351975e-01\n",
      " 3.96807823e-01]\n",
      "Weighted sum of item93_10: 4.640558648067441\n",
      "Weighted sum of item93_11: 4.370485987193722\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x)) \n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "softmax_10 = softmax(item93_10)\n",
    "softmax_11 = softmax(item93_11)\n",
    "weights = [1, 2, 3, 4, 5]  \n",
    "\n",
    "\n",
    "weighted_sum_10 = np.sum(np.array(weights) * softmax_10)\n",
    "weighted_sum_11 = np.sum(np.array(weights) * softmax_11)\n",
    "\n",
    "print(\"Softmax of item93_10:\", softmax_10)\n",
    "print(\"Softmax of item93_11:\", softmax_11)\n",
    "print(\"Weighted sum of item93_10:\", weighted_sum_10)\n",
    "print(\"Weighted sum of item93_11:\", weighted_sum_11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
