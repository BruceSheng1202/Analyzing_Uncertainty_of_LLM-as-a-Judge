{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_number = {\n",
    "    'one': 1,\n",
    "    'two': 2,\n",
    "    'three': 3,\n",
    "    'four': 4,\n",
    "    'five': 5\n",
    "}\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "alpha = 0.10\n",
    "\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# !git clone https://github.com/zlin7/LVD.git\n",
    "%cd LVD\n",
    "# !pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from data.preprocess_small_datasets import pretrain_general\n",
    "from models.regmodel import KernelMLKR\n",
    "from models.conformal import LocalConditional, PIConstructor\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "\n",
    "def range_modification(y_qlow, y_qup, range_low,  range_up):\n",
    "    y_qlow = np.clip(y_qlow, range_low, range_up)\n",
    "    y_qup = np.clip(y_qup, range_low, range_up)\n",
    "    return y_qlow, y_qup\n",
    "\n",
    "def run_experiment(X, y, seed, dataset, dimension):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # X = clr_transform(X)\n",
    "    X = X.to_numpy().astype(np.float32)\n",
    "    y = y.to_numpy().astype(np.float32)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_cal, X_test, y_cal, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "\n",
    "    # X_cal = X_cal[:int(len(X_cal) * cal_size)]\n",
    "    # y_cal = y_cal[:int(len(y_cal) * cal_size)]\n",
    "    \n",
    "    y_cal = y_cal.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    DNN_model, readout_layer = pretrain_general(X_cal, y_cal, seed=0, quiet=True, model_setting=0)\n",
    "    embed_cal = DNN_model.embed(X_cal)\n",
    "    embed_test = DNN_model.embed(X_test)\n",
    "\n",
    "    kernel_model = KernelMLKR(d=10, seed=0, n_iters=500, norm=True, lr=1e-3)\n",
    "    kernel_model.fit(embed_cal, y_cal.flatten()) \n",
    "\n",
    "    lvd = LocalConditional(K_obj=kernel_model)\n",
    "    lvd.fit(embed_cal, y_cal.flatten(), m=readout_layer)\n",
    "\n",
    "    results = lvd.eval(embed_test, y_test.flatten(), lvd.PI, alpha=alpha, quiet=False)\n",
    "\n",
    "    y_qlow = results['lo'].to_numpy()\n",
    "    y_qup = results['hi'].to_numpy()\n",
    "    y_qlow, y_qup = range_modification(y_qlow, y_qup, 1, 5)\n",
    "\n",
    "    intervals = [[(low, high)] for low, high in zip(y_qlow, y_qup)]\n",
    "    print(intervals)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'low':    [iv[0][0] for iv in intervals],\n",
    "        'up':     [iv[0][1] for iv in intervals],\n",
    "        'y_test': y_test.flatten()\n",
    "    })\n",
    "    \n",
    "    df.to_csv(f'LVD_{dataset}_{dimension}_{seed}.csv', index=False)\n",
    "\n",
    "    adjusted_intervals = [\n",
    "    [\n",
    "        (\n",
    "            next((num for num in [1, 2, 3, 4, 5] if abs(low - num) < 0.1), low),\n",
    "            next((num for num in [1, 2, 3, 4, 5] if abs(high - num) < 0.1), high)\n",
    "        )\n",
    "        for low, high in sample_intervals\n",
    "    ]\n",
    "    for sample_intervals in intervals]\n",
    "\n",
    "    intervals = adjusted_intervals\n",
    "\n",
    "    in_interval = [\n",
    "        any(low <= true_value <= high for low, high in sample_intervals)\n",
    "        for sample_intervals, true_value in zip(intervals, y_test)\n",
    "    ]\n",
    "\n",
    "    coverage_rate = np.mean(in_interval)\n",
    "    average_width = np.mean([high - low for sample_intervals in intervals for low, high in sample_intervals])  \n",
    "\n",
    "    print(f\"Seed: {seed}, Width: {average_width:.4f}, Coverage: {coverage_rate:.4f}\")\n",
    "\n",
    "    return average_width, coverage_rate\n",
    "\n",
    "def calculate_statistics(X, y, num_runs=100, seed_start=1, dataset = 'Summeval', dimension = 'consistency'):\n",
    "    from tqdm import tqdm\n",
    "    width = []\n",
    "    coverage = []\n",
    "    for i in tqdm(range(num_runs), desc=\"Running experiments\"):\n",
    "        seed = seed_start + i\n",
    "        try:\n",
    "            average_width, coverage_rate = run_experiment(X, y, seed, dataset, dimension)\n",
    "            width.append(average_width)\n",
    "            coverage.append(coverage_rate)\n",
    "        except IndexError as e:\n",
    "            print(f\"Skipping seed {seed} due to error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    mean_width = np.mean(width)\n",
    "    std_width = np.std(width)\n",
    "    mean_coverage = np.mean(coverage)\n",
    "    std_coverage = np.std(coverage)\n",
    "\n",
    "    print(\"\\nSummary of LVD:\")\n",
    "    print(f\"Width: {mean_width:.4f}, {std_width:.4f}\")\n",
    "    print(f\"Coverage: {mean_coverage:.4f}, {std_coverage:.4f}\")\n",
    "\n",
    "    return  width, coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 'consistency'\n",
    "dataset = 'Dialsumm'\n",
    "\n",
    "# folder_path = f'../data_results/prompt_logits/data_logits/{dataset}/'\n",
    "# file_path = os.path.join(folder_path, f\"{dataset}_{dimension}.csv\")\n",
    "folder_path = f'../model_logits/qwen/'\n",
    "file_path = os.path.join(folder_path, f\"{dataset}_{dimension}_logits.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "width, coverage = calculate_statistics(X, y, 30, 1, dataset, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# folder_path = '../data_results/prompt_logits/data_logits/Socreval'\n",
    "folder_path = f'../model_logits/qwen/'\n",
    "\n",
    "data = {}\n",
    "for dimension in [\"cosmos\", \"drop\", \"esnli\", \"gsm8k\"]:\n",
    "        file_path = os.path.join(folder_path, f\"SocREval_{dimension}_logits.csv\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "        width, coverage = calculate_statistics(X, y, num_runs=30, seed_start=1, dimension=dimension, dataset='SocREval')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
