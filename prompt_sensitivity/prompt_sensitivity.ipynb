{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "alpha = 0.10\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# !wget https://files.pythonhosted.org/packages/py3/R/R2CCP/R2CCP-0.0.8-py3-none-any.whl\n",
    "# !pip install R2CCP-0.0.8-py3-none-any.whl --no-deps\n",
    "import os\n",
    "os.makedirs('model_paths', exist_ok=True)\n",
    "\n",
    "# !pip install configargparse pytorch_lightning torchvision\n",
    "from R2CCP.main import R2CCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05864e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_intervals(sample_intervals):\n",
    "    if not sample_intervals:\n",
    "        return (1,5)\n",
    "    lows = [low for low, high in sample_intervals]\n",
    "    highs = [high for low, high in sample_intervals]\n",
    "    return (min(lows), max(highs))\n",
    "\n",
    "def range_modification(y_qlow, y_qup, range_low,  range_up):\n",
    "    y_qlow = np.clip(y_qlow, range_low, range_up)\n",
    "    y_qup = np.clip(y_qup, range_low, range_up)\n",
    "    return y_qlow, y_qup\n",
    "\n",
    "def run_experiment(X, y, dimension, cot, model_name, seed):\n",
    "\n",
    "    X = X.to_numpy().astype(np.float32)\n",
    "    y = y.to_numpy().astype(np.float32)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_cal, X_test, y_cal, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    if os.path.exists('model_paths/model_save_destination.pth'):\n",
    "        os.remove('model_paths/model_save_destination.pth')\n",
    "\n",
    "    model = R2CCP({'model_path': 'model_paths/model_save_destination.pth', 'max_epochs': 100, 'alpha': 0.1})\n",
    "    model.fit(X_cal, y_cal.flatten())\n",
    "    intervals = model.get_intervals(X_test)\n",
    "    intervals = [merge_intervals(sample_intervals) for sample_intervals in intervals]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'low':    [iv[0] for iv in intervals],\n",
    "        'up':     [iv[1] for iv in intervals],\n",
    "        'y_test': y_test\n",
    "    })\n",
    "\n",
    "    df.to_csv(f'R2CCP_{model_name}_{dimension}_prompt{cot}_sensitivity_{seed}.csv', index=False)\n",
    "\n",
    "    in_interval = [\n",
    "        (low <= y_true <= high)\n",
    "        for (low, high), y_true in zip(intervals, y_test)\n",
    "    ]\n",
    "    coverage_rate  = np.mean(in_interval)\n",
    "    average_width = np.mean([high - low for low, high in intervals])\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Width: {average_width:.4f}, Coverage: {coverage_rate:.4f}\")\n",
    "\n",
    "    return average_width, coverage_rate\n",
    "\n",
    "\n",
    "def calculate_statistics(X, y, num_runs, seed_start, dimension, cot, model_name):\n",
    "    from tqdm import tqdm\n",
    "    width = []\n",
    "    coverage = []\n",
    "    for i in tqdm(range(num_runs), desc=\"Running experiments\"):\n",
    "        seed = seed_start + i\n",
    "        try:\n",
    "            average_width, coverage_rate = run_experiment(X, y, dimension, cot, model_name, seed)\n",
    "            width.append(average_width)\n",
    "            coverage.append(coverage_rate)\n",
    "        except IndexError as e:\n",
    "            print(f\"Skipping seed {seed} due to error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    mean_width = np.mean(width)\n",
    "    std_width = np.std(width)\n",
    "    mean_coverage = np.mean(coverage)\n",
    "    std_coverage = np.std(coverage)\n",
    "\n",
    "    print(\"\\nSummary of R2CCP:\")\n",
    "    print(f\"Width: {mean_width:.4f}, {std_width:.4f}\")\n",
    "    print(f\"Coverage: {mean_coverage:.4f}, {std_coverage:.4f}\")\n",
    "\n",
    "    return  mean_width, std_width, mean_coverage, std_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "label = pd.read_csv('label_summeval.csv')\n",
    "for dimension in {'consistency', 'coherence'}:\n",
    "    print(f\"Processing dimension: {dimension}\")\n",
    "    y = label[dimension]\n",
    "    for model_name in {'4o'}:\n",
    "        all_logits = pd.read_csv(f'logits/{model_name}_{dimension}.csv')\n",
    "        for cot in range(5):\n",
    "            X = all_logits.iloc[cot::5]\n",
    "            mean_width, std_width, mean_coverage, std_coverage = calculate_statistics(X, y, 30, 1, dimension, cot, model_name)\n",
    "\n",
    "            results.append({\n",
    "                'model_name': model_name,\n",
    "                'cot': cot,\n",
    "                'dimension': dimension,\n",
    "                'mean_width': mean_width,\n",
    "                'std_width': std_width,\n",
    "                'mean_coverage': mean_coverage,\n",
    "                'std_coverage': std_coverage\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d744d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "label = pd.read_csv('label_summeval.csv')\n",
    "for dimension in {'fluency', 'relevance'}:\n",
    "    print(f\"Processing dimension: {dimension}\")\n",
    "    y = label[dimension]\n",
    "    for model_name in {'4o'}:\n",
    "        all_logits = pd.read_csv(f'logits/{model_name}_{dimension}.csv')\n",
    "        for cot in range(5):\n",
    "            X = all_logits.iloc[cot::5]\n",
    "            mean_width, std_width, mean_coverage, std_coverage = calculate_statistics(X, y, 30, 1, dimension, cot, model_name)\n",
    "\n",
    "            results.append({\n",
    "                'model_name': model_name,\n",
    "                'cot': cot,\n",
    "                'dimension': dimension,\n",
    "                'mean_width': mean_width,\n",
    "                'std_width': std_width,\n",
    "                'mean_coverage': mean_coverage,\n",
    "                'std_coverage': std_coverage\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00260aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "label = pd.read_csv('label_summeval.csv')\n",
    "for dimension in {'consistency', 'coherence'}:\n",
    "    print(f\"Processing dimension: {dimension}\")\n",
    "    y = label[dimension]\n",
    "    for model_name in {'4omini'}:\n",
    "        all_logits = pd.read_csv(f'logits/{model_name}_{dimension}.csv')\n",
    "        for cot in range(5):\n",
    "            X = all_logits.iloc[cot::5]\n",
    "            mean_width, std_width, mean_coverage, std_coverage = calculate_statistics(X, y, 30, 1, dimension, cot, model_name)\n",
    "\n",
    "            results.append({\n",
    "                'model_name': model_name,\n",
    "                'cot': cot,\n",
    "                'dimension': dimension,\n",
    "                'mean_width': mean_width,\n",
    "                'std_width': std_width,\n",
    "                'mean_coverage': mean_coverage,\n",
    "                'std_coverage': std_coverage\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297191e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "label = pd.read_csv('label_summeval.csv')\n",
    "for dimension in {'fluency', 'relevance'}:\n",
    "    print(f\"Processing dimension: {dimension}\")\n",
    "    y = label[dimension]\n",
    "    for model_name in {'4omini'}:\n",
    "        all_logits = pd.read_csv(f'logits/{model_name}_{dimension}.csv')\n",
    "        for cot in range(5):\n",
    "            X = all_logits.iloc[cot::5]\n",
    "            mean_width, std_width, mean_coverage, std_coverage = calculate_statistics(X, y, 30, 1, dimension, cot, model_name)\n",
    "\n",
    "            results.append({\n",
    "                'model_name': model_name,\n",
    "                'cot': cot,\n",
    "                'dimension': dimension,\n",
    "                'mean_width': mean_width,\n",
    "                'std_width': std_width,\n",
    "                'mean_coverage': mean_coverage,\n",
    "                'std_coverage': std_coverage\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3153d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cot   model    dimension  interval_width_mean  interval_width_std  \\\n",
      "0    0      4o  consistency             0.841784            0.215207   \n",
      "1    0      4o    coherence             3.094161            0.148751   \n",
      "2    0      4o      fluency             1.086002            0.221702   \n",
      "3    0      4o    relevance             2.409371            0.150009   \n",
      "4    0  4omini  consistency             0.827695            0.262389   \n",
      "5    0  4omini    coherence             2.968898            0.141206   \n",
      "6    0  4omini      fluency             1.062315            0.244633   \n",
      "7    0  4omini    relevance             2.359884            0.130038   \n",
      "8    1      4o  consistency             0.802447            0.245293   \n",
      "9    1      4o    coherence             2.976335            0.156964   \n",
      "10   1      4o      fluency             1.052982            0.229471   \n",
      "11   1      4o    relevance             2.371231            0.108815   \n",
      "12   1  4omini  consistency             0.810368            0.210735   \n",
      "13   1  4omini    coherence             3.023990            0.158455   \n",
      "14   1  4omini      fluency             1.071473            0.271617   \n",
      "15   1  4omini    relevance             2.373002            0.142804   \n",
      "16   2      4o  consistency             0.866071            0.288338   \n",
      "17   2      4o    coherence             2.980306            0.135366   \n",
      "18   2      4o      fluency             1.067898            0.229302   \n",
      "19   2      4o    relevance             2.395028            0.159050   \n",
      "20   2  4omini  consistency             0.813940            0.240665   \n",
      "21   2  4omini    coherence             2.977678            0.120782   \n",
      "22   2  4omini      fluency             1.053802            0.257871   \n",
      "23   2  4omini    relevance             2.390831            0.129751   \n",
      "24   3      4o  consistency             0.881360            0.335825   \n",
      "25   3      4o    coherence             3.023726            0.120046   \n",
      "26   3      4o      fluency             1.050254            0.265053   \n",
      "27   3      4o    relevance             2.381499            0.143679   \n",
      "28   3  4omini  consistency             0.882953            0.312351   \n",
      "29   3  4omini    coherence             3.033677            0.135465   \n",
      "30   3  4omini      fluency             1.065780            0.261254   \n",
      "31   3  4omini    relevance             2.417276            0.150502   \n",
      "32   4      4o  consistency             0.811619            0.268167   \n",
      "33   4      4o    coherence             3.048083            0.129283   \n",
      "34   4      4o      fluency             1.047308            0.237564   \n",
      "35   4      4o    relevance             2.390988            0.148043   \n",
      "36   4  4omini  consistency             0.845361            0.282643   \n",
      "37   4  4omini    coherence             3.015631            0.118919   \n",
      "38   4  4omini      fluency             1.086048            0.269955   \n",
      "39   4  4omini    relevance             2.420475            0.139407   \n",
      "\n",
      "    coverage_rate_mean  coverage_rate_std  significant_test  \n",
      "0             0.900603           0.020326      1.009162e-05  \n",
      "1             0.896121           0.029167      1.883175e-09  \n",
      "2             0.899375           0.023311      3.050659e-07  \n",
      "3             0.895208           0.029369      3.657471e-09  \n",
      "4             0.896595           0.024419      1.793127e-07  \n",
      "5             0.887931           0.026538      7.391283e-13  \n",
      "6             0.896208           0.020858      3.559479e-08  \n",
      "7             0.897625           0.024810      3.559479e-08  \n",
      "8             0.895905           0.020637      1.793127e-07  \n",
      "9             0.885647           0.028908      1.924875e-15  \n",
      "10            0.899500           0.019977      3.050659e-07  \n",
      "11            0.891917           0.023721      2.625307e-11  \n",
      "12            0.897026           0.020497      1.793127e-07  \n",
      "13            0.893017           0.029472      1.581656e-10  \n",
      "14            0.898708           0.022606      1.528449e-05  \n",
      "15            0.895458           0.028583      3.657471e-09  \n",
      "16            0.897457           0.021117      1.793127e-07  \n",
      "17            0.893534           0.028128      1.581656e-10  \n",
      "18            0.900000           0.023537      3.050659e-07  \n",
      "19            0.893417           0.029935      3.306665e-10  \n",
      "20            0.896595           0.022497      1.962613e-08  \n",
      "21            0.891379           0.025485      1.581656e-10  \n",
      "22            0.896167           0.020720      3.657471e-09  \n",
      "23            0.896500           0.027086      2.302323e-06  \n",
      "24            0.900474           0.021348      1.436845e-06  \n",
      "25            0.895302           0.023060      1.793127e-07  \n",
      "26            0.899542           0.022725      3.050659e-07  \n",
      "27            0.896542           0.028087      2.302323e-06  \n",
      "28            0.900948           0.021771      1.009162e-05  \n",
      "29            0.894569           0.026931      1.883175e-09  \n",
      "30            0.898458           0.018859      3.559479e-08  \n",
      "31            0.898333           0.026687      3.657471e-09  \n",
      "32            0.897371           0.022578      1.883175e-09  \n",
      "33            0.896509           0.026460      1.793127e-07  \n",
      "34            0.898042           0.021044      3.306665e-10  \n",
      "35            0.898708           0.031988      1.528449e-05  \n",
      "36            0.897328           0.021178      1.436845e-06  \n",
      "37            0.890862           0.024949      1.581656e-10  \n",
      "38            0.897708           0.022354      3.306665e-10  \n",
      "39            0.899792           0.026150      1.528449e-05  \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "\n",
    "results = []\n",
    "\n",
    "for cot in ['0', '1', '2', '3', '4']:\n",
    "    for model in ['4o','4omini']:\n",
    "            for dimension in ['consistency', 'coherence', 'fluency', 'relevance']:\n",
    "                coverages = []\n",
    "                widths = []\n",
    "                for seed in range(31):\n",
    "                    csv_path = f'./R2CCP_{model}_{dimension}_prompt{cot}_sensitivity_{seed}.csv'\n",
    "                    if os.path.exists(csv_path):\n",
    "                        df = pd.read_csv(csv_path)\n",
    "                        df = df.rename(columns={'low': 'y_qlow', 'up': 'y_qup'})\n",
    "                        df['y_test'] = round(df['y_test'], 2)\n",
    "                        df['y_qlow'] = round(df['y_qlow'], 2)\n",
    "                        df['y_qup'] = round(df['y_qup'], 2)\n",
    "                        coverage = ((df['y_test'] >= df['y_qlow']) & (df['y_test'] <= df['y_qup'])).mean()\n",
    "                        width = (df['y_qup'] - df['y_qlow']).mean()\n",
    "                        coverages.append(coverage)\n",
    "                        widths.append(width)\n",
    "                if coverages and widths:\n",
    "                    results.append({\n",
    "                        'cot': cot,\n",
    "                        'model': model,\n",
    "                        'dimension': dimension,\n",
    "                        'interval_width_mean': sum(widths) / len(widths),\n",
    "                        'interval_width_std': pd.Series(widths).std(),\n",
    "                        'coverage_rate_mean': sum(coverages) / len(coverages),\n",
    "                        'coverage_rate_std': pd.Series(coverages).std(),\n",
    "                        'significant_test': binomtest(sum(c >= 0.9 for c in coverages), len(coverages), 0.9, alternative='two-sided').pvalue\n",
    "                    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f75fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cot   model    dimension  interval_width_mean  interval_width_std  \\\n",
      "0    0      4o  consistency             0.841784            0.215207   \n",
      "1    0      4o    coherence             3.094161            0.148751   \n",
      "2    0      4o      fluency             1.086002            0.221702   \n",
      "3    0      4o    relevance             2.409371            0.150009   \n",
      "4    0  4omini  consistency             0.827695            0.262389   \n",
      "5    0  4omini    coherence             2.968898            0.141206   \n",
      "6    0  4omini      fluency             1.062315            0.244633   \n",
      "7    0  4omini    relevance             2.359884            0.130038   \n",
      "8    1      4o  consistency             0.802447            0.245293   \n",
      "9    1      4o    coherence             2.976335            0.156964   \n",
      "10   1      4o      fluency             1.052982            0.229471   \n",
      "11   1      4o    relevance             2.371231            0.108815   \n",
      "12   1  4omini  consistency             0.810368            0.210735   \n",
      "13   1  4omini    coherence             3.023990            0.158455   \n",
      "14   1  4omini      fluency             1.071473            0.271617   \n",
      "15   1  4omini    relevance             2.373002            0.142804   \n",
      "16   2      4o  consistency             0.866071            0.288338   \n",
      "17   2      4o    coherence             2.980306            0.135366   \n",
      "18   2      4o      fluency             1.067898            0.229302   \n",
      "19   2      4o    relevance             2.395028            0.159050   \n",
      "20   2  4omini  consistency             0.813940            0.240665   \n",
      "21   2  4omini    coherence             2.977678            0.120782   \n",
      "22   2  4omini      fluency             1.053802            0.257871   \n",
      "23   2  4omini    relevance             2.390831            0.129751   \n",
      "24   3      4o  consistency             0.881360            0.335825   \n",
      "25   3      4o    coherence             3.023726            0.120046   \n",
      "26   3      4o      fluency             1.050254            0.265053   \n",
      "27   3      4o    relevance             2.381499            0.143679   \n",
      "28   3  4omini  consistency             0.882953            0.312351   \n",
      "29   3  4omini    coherence             3.033677            0.135465   \n",
      "30   3  4omini      fluency             1.065780            0.261254   \n",
      "31   3  4omini    relevance             2.417276            0.150502   \n",
      "32   4      4o  consistency             0.811619            0.268167   \n",
      "33   4      4o    coherence             3.048083            0.129283   \n",
      "34   4      4o      fluency             1.047308            0.237564   \n",
      "35   4      4o    relevance             2.390988            0.148043   \n",
      "36   4  4omini  consistency             0.845361            0.282643   \n",
      "37   4  4omini    coherence             3.015631            0.118919   \n",
      "38   4  4omini      fluency             1.086048            0.269955   \n",
      "39   4  4omini    relevance             2.420475            0.139407   \n",
      "\n",
      "    coverage_rate_mean  coverage_rate_std  significant_test  \n",
      "0             0.900603           0.020326      1.009162e-05  \n",
      "1             0.896121           0.029167      1.883175e-09  \n",
      "2             0.899375           0.023311      3.050659e-07  \n",
      "3             0.895208           0.029369      3.657471e-09  \n",
      "4             0.896595           0.024419      1.793127e-07  \n",
      "5             0.887931           0.026538      7.391283e-13  \n",
      "6             0.896208           0.020858      3.559479e-08  \n",
      "7             0.897625           0.024810      3.559479e-08  \n",
      "8             0.895905           0.020637      1.793127e-07  \n",
      "9             0.885647           0.028908      1.924875e-15  \n",
      "10            0.899500           0.019977      3.050659e-07  \n",
      "11            0.891917           0.023721      2.625307e-11  \n",
      "12            0.897026           0.020497      1.793127e-07  \n",
      "13            0.893017           0.029472      1.581656e-10  \n",
      "14            0.898708           0.022606      1.528449e-05  \n",
      "15            0.895458           0.028583      3.657471e-09  \n",
      "16            0.897457           0.021117      1.793127e-07  \n",
      "17            0.893534           0.028128      1.581656e-10  \n",
      "18            0.900000           0.023537      3.050659e-07  \n",
      "19            0.893417           0.029935      3.306665e-10  \n",
      "20            0.896595           0.022497      1.962613e-08  \n",
      "21            0.891379           0.025485      1.581656e-10  \n",
      "22            0.896167           0.020720      3.657471e-09  \n",
      "23            0.896500           0.027086      2.302323e-06  \n",
      "24            0.900474           0.021348      1.436845e-06  \n",
      "25            0.895302           0.023060      1.793127e-07  \n",
      "26            0.899542           0.022725      3.050659e-07  \n",
      "27            0.896542           0.028087      2.302323e-06  \n",
      "28            0.900948           0.021771      1.009162e-05  \n",
      "29            0.894569           0.026931      1.883175e-09  \n",
      "30            0.898458           0.018859      3.559479e-08  \n",
      "31            0.898333           0.026687      3.657471e-09  \n",
      "32            0.897371           0.022578      1.883175e-09  \n",
      "33            0.896509           0.026460      1.793127e-07  \n",
      "34            0.898042           0.021044      3.306665e-10  \n",
      "35            0.898708           0.031988      1.528449e-05  \n",
      "36            0.897328           0.021178      1.436845e-06  \n",
      "37            0.890862           0.024949      1.581656e-10  \n",
      "38            0.897708           0.022354      3.306665e-10  \n",
      "39            0.899792           0.026150      1.528449e-05  \n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
