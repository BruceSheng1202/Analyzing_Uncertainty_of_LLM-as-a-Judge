{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huanx\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huanx\\python\\LLMCP\\chr\n",
      "Is CUDA available? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huanx\\AppData\\Local\\Temp\\ipykernel_38484\\3763401771.py:29: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "word_to_number = {\n",
    "    'one': 1,\n",
    "    'two': 2,\n",
    "    'three': 3,\n",
    "    'four': 4,\n",
    "    'five': 5\n",
    "}\n",
    "\n",
    "alpha = 0.10\n",
    "\n",
    "# !git clone https://github.com/msesia/chr.git\n",
    "%cd chr\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import torch\n",
    "\n",
    "print(\"Is CUDA available? {}\".format(torch.cuda.is_available()))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "#Edit the black_boxes.py: 'import torch.tensor as tensor' → 'from torch import tensor'\n",
    "#Edit the black_boxes.py: 'from skgarden import RandomForestQuantileRegressor' → 'from sklearn.linear_model import QuantileRegressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\huanx\\\\python\\\\LLMCP\\\\chr'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rpy2 in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.6.1)\n",
      "Requirement already satisfied: rpy2-rinterface>=3.6.1 in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rpy2) (3.6.1)\n",
      "Requirement already satisfied: rpy2-robjects>=3.6.1 in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rpy2) (3.6.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rpy2) (24.1)\n",
      "Requirement already satisfied: cffi>=1.15.1 in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rpy2-rinterface>=3.6.1->rpy2) (1.17.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rpy2-robjects>=3.6.1->rpy2) (3.1.3)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rpy2-robjects>=3.6.1->rpy2) (5.3.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from cffi>=1.15.1->rpy2-rinterface>=3.6.1->rpy2) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->rpy2-robjects>=3.6.1->rpy2) (2.1.5)\n",
      "Requirement already satisfied: tzdata in c:\\users\\huanx\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tzlocal->rpy2-robjects>=3.6.1->rpy2) (2024.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\huanx\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "!pip install rpy2\n",
    "from chr.black_boxes import QNet\n",
    "from chr.histogram import Histogram\n",
    "from chr.grey_boxes import HistogramAccumulator\n",
    "\n",
    "\n",
    "def range_modification(y_qlow, y_qup, range_low,  range_up):\n",
    "    y_qlow = np.clip(y_qlow, range_low, range_up)\n",
    "    y_qup = np.clip(y_qup, range_low, range_up)\n",
    "    return y_qlow, y_qup\n",
    "\n",
    "def run_experiment(X, y, seed, dataset='Summeval', dimension='consistency'):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    X = X.to_numpy().astype(np.float32)\n",
    "    y = y.to_numpy().astype(np.float32)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_cal, X_test, y_cal, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "\n",
    "    grid_quantiles = np.arange(0.01, 1.0, 0.01)\n",
    "\n",
    "    bbox = QNet(\n",
    "        grid_quantiles,\n",
    "        X_cal.shape[1],\n",
    "        no_crossing=True,\n",
    "        batch_size=32,\n",
    "        dropout=0.1,\n",
    "        num_epochs=1000,\n",
    "        learning_rate=0.0005,\n",
    "        num_hidden=256,\n",
    "        calibrate=False\n",
    "    )\n",
    "\n",
    "    bbox.fit(X_cal, y_cal)\n",
    "\n",
    "    grid_histogram = np.arange(0, 6, 0.1)\n",
    "\n",
    "    hist = Histogram(grid_quantiles, grid_histogram)\n",
    "\n",
    "    Q_test = bbox.predict(X_test)\n",
    "\n",
    "    histogram_test = hist.compute_histogram(Q_test, 0, 6, 0.001)\n",
    "\n",
    "    accumulator = HistogramAccumulator(histogram_test, grid_histogram, alpha=alpha, delta_alpha=0.01)\n",
    "\n",
    "    epsilon = np.random.uniform(low=0.0, high=1.0, size=X_test.shape[0])\n",
    "    S, bands = accumulator.predict_intervals(alpha, epsilon=epsilon)\n",
    "    S_int = [np.arange(S[i][0],S[i][1]+1) for i in range(len(S))]\n",
    "    intervals_crch = np.array([[grid_histogram[S_int[i]-1][0],grid_histogram[S_int[i]][-1]] for i in range(len(S_int))])\n",
    "\n",
    "    y_qlow = np.min(intervals_crch, axis=1)\n",
    "    y_qup = np.max(intervals_crch, axis=1)\n",
    "\n",
    "    y_qlow, y_qup = range_modification(y_qlow, y_qup, 1, 5)\n",
    "    intervals = [\n",
    "    [(low, high)] for low, high in zip(y_qlow, y_qup)\n",
    "]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'low':    [iv[0][0] for iv in intervals],\n",
    "        'up':     [iv[0][1] for iv in intervals],\n",
    "        'y_test': y_test\n",
    "    })\n",
    "\n",
    "    df.to_csv(f'CHR_{dataset}_{dimension}_{seed}.csv', index=False)\n",
    "\n",
    "    adjusted_intervals = [\n",
    "    [\n",
    "        (\n",
    "            next((num for num in [1, 2, 3, 4, 5] if abs(low - num) < 0.1), low),\n",
    "            next((num for num in [1, 2, 3, 4, 5] if abs(high - num) < 0.1), high)\n",
    "        )\n",
    "        for low, high in sample_intervals\n",
    "    ]\n",
    "    for sample_intervals in intervals]\n",
    "\n",
    "    intervals = adjusted_intervals\n",
    "\n",
    "    in_interval = [\n",
    "        any(low <= true_value <= high for low, high in sample_intervals)\n",
    "        for sample_intervals, true_value in zip(intervals, y_test)\n",
    "    ]\n",
    "\n",
    "    coverage_rate = np.mean(in_interval)\n",
    "    average_width = np.mean([high - low for sample_intervals in intervals for low, high in sample_intervals])  \n",
    "\n",
    "\n",
    "\n",
    "    return average_width, coverage_rate\n",
    "\n",
    "def calculate_statistics(X, y, num_runs=100, seed_start=1, dataset='Summeval', dimension='consistency'):\n",
    "    from tqdm import tqdm\n",
    "    width = []\n",
    "    coverage = []\n",
    "    for i in tqdm(range(num_runs), desc=\"Running experiments\"):\n",
    "        seed = seed_start + i\n",
    "        average_width, coverage_rate = run_experiment(X, y, seed, dataset, dimension)\n",
    "        width.append(average_width)\n",
    "        coverage.append(coverage_rate)\n",
    "\n",
    "    mean_width = np.mean(width)\n",
    "    std_width = np.std(width)\n",
    "    mean_coverage = np.mean(coverage)\n",
    "    std_coverage = np.std(coverage)\n",
    "\n",
    "    print(\"\\nSummary of CHR:\")\n",
    "    print(f\"Width: {mean_width:.4f}, {std_width:.4f}\")\n",
    "    print(f\"Coverage: {mean_coverage:.4f}, {std_coverage:.4f}\")\n",
    "\n",
    "    return  width, coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiments:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples and 5 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:00<00:00, 16.57it/s]\n",
      "Running experiments: 100%|██████████| 1/1 [01:01<00:00, 61.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of CHR:\n",
      "Width: 1.5899, 0.0000\n",
      "Coverage: 0.7913, 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dimension = 'relevance'\n",
    "dataset = 'Summeval'\n",
    "\n",
    "# folder_path = f'../data_results/prompt_logits/data_logits/{dataset}/'\n",
    "# file_path = os.path.join(folder_path, f\"{dataset}_{dimension}.csv\")\n",
    "folder_path = f'../model_logits/qwen/'\n",
    "file_path = os.path.join(folder_path, f\"{dataset}_{dimension}_logits.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "width, coverage = calculate_statistics(X, y, 1, 1, dataset, dimension)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
